import os
import time
import requests
from bs4 import BeautifulSoup
from openpyxl import Workbook
import xml.etree.ElementTree as ET

TG_TOKEN = os.getenv("TG_TOKEN")
TG_CHAT_ID = os.getenv("TG_CHAT_ID")
HEADERS = {"User-Agent": "Mozilla/5.0"}

SITEMAP_URL = "https://materialedidactice.ro/sitemap_index.xml"

# ================= HELPER FUNCTIONS =================

def send_telegram_message(msg: str):
    """Trimite alertƒÉ pe Telegram"""
    if not TG_TOKEN or not TG_CHAT_ID:
        print("‚ö†Ô∏è TG_TOKEN sau TG_CHAT_ID lipsesc.")
        return
    url = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
    try:
        requests.post(url, data={"chat_id": TG_CHAT_ID, "text": msg})
        print("‚úÖ AlertƒÉ trimisƒÉ pe Telegram")
    except Exception as e:
        print(f"‚ùå Eroare la trimiterea alertei: {e}")


def get_soup(url):
    """ReturneazƒÉ BeautifulSoup pentru o paginƒÉ"""
    r = requests.get(url, headers=HEADERS, timeout=20)
    r.raise_for_status()
    return BeautifulSoup(r.text, "lxml")


def get_sitemap_links():
    """Cite»ôte sitemap_index »ôi returneazƒÉ linkurile din product-sitemap"""
    print(f"üì• Descarc sitemap principal: {SITEMAP_URL}")
    r = requests.get(SITEMAP_URL, headers=HEADERS, timeout=20)
    r.raise_for_status()
    root = ET.fromstring(r.content)
    ns = {"ns": "http://www.sitemaps.org/schemas/sitemap/0.9"}
    links = []
    for loc in root.findall("ns:sitemap/ns:loc", ns):
        url = loc.text.strip()
        if "product-sitemap" in url:
            print(f"   ‚Ü≥ verific {url}")
            r2 = requests.get(url, headers=HEADERS, timeout=20)
            r2.raise_for_status()
            subroot = ET.fromstring(r2.content)
            for u in subroot.findall("ns:url/ns:loc", ns):
                links.append(u.text.strip())
    return links


def parse_product(url):
    """Extrage datele unui produs, inclusiv codul SKU"""
    # sƒÉrim peste fi»ôiere media
    if any(url.lower().endswith(ext) for ext in [".jpg", ".jpeg", ".png", ".gif", ".pdf", ".webp"]):
        raise ValueError("Link media, nu produs")

    soup = get_soup(url)
    title_tag = soup.select_one("h1.product_title")
    if not title_tag:
        raise ValueError("Nu e paginƒÉ de produs")

    title = title_tag.get_text(strip=True)

    # Cod produs (SKU)
    sku_elem = soup.select_one("span.sku")
    cod = sku_elem.get_text(strip=True) if sku_elem else ""

    # Pre»õuri
    pret_initial, pret_curent = "", ""
    price_block = soup.select_one("p.price")
    if price_block:
        ins = price_block.select_one("ins .woocommerce-Price-amount")
        del_tag = price_block.select_one("del .woocommerce-Price-amount")
        if ins:
            pret_curent = ins.get_text(" ", strip=True)
        else:
            span = price_block.select_one(".woocommerce-Price-amount")
            pret_curent = span.get_text(" ", strip=True) if span else ""
        if del_tag:
            pret_initial = del_tag.get_text(" ", strip=True)

    # Descriere
    descriere = ""
    desc_block = soup.select_one("#tab-description")
    if desc_block:
        descriere = desc_block.get_text(" ", strip=True)

    return {
        "Denumire": title,
        "Cod produs": cod,
        "Pre»õ ini»õial": pret_initial,
        "Pre»õ curent": pret_curent,
        "Descriere": descriere,
        "URL": url
    }


def save_to_excel(data, filename):
    """SalveazƒÉ datele √Æntr-un fi»ôier Excel"""
    wb = Workbook()
    ws = wb.active
    ws.append(["Denumire", "Cod produs", "Pre»õ ini»õial", "Pre»õ curent", "Descriere", "URL"])
    for row in data:
        ws.append([
            row.get("Denumire", ""),
            row.get("Cod produs", ""),
            row.get("Pre»õ ini»õial", ""),
            row.get("Pre»õ curent", ""),
            row.get("Descriere", ""),
            row.get("URL", "")
        ])
    wb.save(filename)
    print(f"üìä Datele au fost salvate √Æn {filename}")


# ================= MAIN =================

def main():
    print("=== √éncep scanarea site-ului prin sitemap ===")
    links = get_sitemap_links()
    print(f"‚úÖ Am gƒÉsit {len(links)} linkuri √Æn sitemap.")

    produse = []
    for i, url in enumerate(links, 1):
        print(f"‚û°Ô∏è Cer {url}")
        try:
            produs = parse_product(url)
            produse.append(produs)
            print(f"[{i}/{len(links)}] {produs['Denumire']} (SKU: {produs['Cod produs']})")
        except Exception as e:
            print(f"Eroare la {url}: {e}")

        # delay pentru siguran»õƒÉ
        time.sleep(5)

        # salvare par»õialƒÉ la fiecare 1000 produse
        if i % 1000 == 0:
            fname = f"produse_partial_{i}.xlsx"
            save_to_excel(produse, fname)
            print(f"üíæ Salvare par»õialƒÉ la {i} produse.")

    # salvƒÉm fi»ôierele finale
    save_to_excel(produse, "produse.xlsx")
    save_to_excel(produse, "produse_noi.xlsx")

    send_telegram_message("‚úÖ Scanare completƒÉ. Produse procesate: %d" % len(produse))


if __name__ == "__main__":
    main()
